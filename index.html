<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a,strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }

    /*
    span.highlight {
        background-color: #ffffd0;
    }

    tr.highlight {
      background-color: #ffffd0;
    } */

    .people {
      margin: auto;
      text-align: center;
    }

    /* 141px for 5 images [136px for img height/width */
    /* 116px for 6 images [111px for img height/width] */
    /* actual website: 114px for 6 images [109px for img height/width] */
    .people a[href] {
      display: inline-block;
      width: 114px;
      padding: 4 4 4 4;
      text-align: center;
      text-align-last: center;
      vertical-align: top;
    }
    .people a img {
      width: 109px;
      height: 109px;
      object-fit: cover;
    }

  </style>
  <!--<link rel="icon" type="image/png" href="images/interactive_sim_2.png">-->
  <link rel="icon" type="image/png" href="media/color_headshot_favicon.png">
  <title>Ruth Fong</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-RS81Q5DB6F"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-RS81Q5DB6F');
  </script>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <!--<tr onmouseout="headshot_stop()" onmouseover="headshot_start()">-->
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Ruth Fong</name>
          <!--<br>
          ruthfong at robots dot ox dot ac dot uk-->
        </p>
        <p>
          I am a teaching faculty member in the <a href="https://www.cs.princeton.edu/">Department of Computer Science</a> at <a href="https://www.princeton.edu/">Princeton University</a>, where I teach intro and AIML CS courses and conduct research in computer vision and machine learning with a focus on explainable AI. At Princeton, I lead the <a href="">Looking Glass Lab</a> as well as collaborate with Professor <a href="https://www.cs.princeton.edu/~olgarus/">Olga Russakovsky</a> and the <a href="https://visualai.princeton.edu/">Visual AI Lab</a>.
        </p>
        <p>
          I completed my PhD in the <a href="http://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group</a> at the <a href="http://www.ox.ac.uk/">University of Oxford</a>, where I was advised by <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a> and funded by the <a href="https://www.rhodeshouse.ox.ac.uk/">Rhodes Trust</a> and <a href="https://www.openphilanthropy.org/">Open Philanthropy</a>. Also at Oxford, I earned a Masters in Neuroscience, where I worked with <a href="https://www.ndcn.ox.ac.uk/team/rafal-bogacz">Rafal Bogacz</a>, <a href="https://www.dpag.ox.ac.uk/team/benjamin-willmore">Ben Willmore</a>, and  <a href="https://scholar.google.com/citations?user=GUALUxwAAAAJ">Nicol Harper</a>.
          I received a Bachelors in Computer Science at <a href="https://www.harvard.edu">Harvard University</a>, where I worked with <a href="http://coxlab.org/">David Cox</a> and <a href="https://www.wjscheirer.com/">Walter Scheirer</a>.
        </p>
        <p>
          <b>Funding acknowledgements:</b> Looking Glass Lab is grateful to Princeton SEAS and Open Philanthropy for genereous support of our research.
        </p>
        <p>
          <b>Postdoc hiring:</b> Looking Glass Lab and <a href="https://visualai.princeton.edu/">Visual AI Lab</a> are hiring a joint postdoc to work on topics in interpretability and fairness. To apply, please fill out the <a href="https://bit.ly/vai-lg-postdoc">application form</a>.
          We particularly welcome applicants from underrepresented groups.
        </p>
        <!--<p>I'm also supported by <a href="https://brianzhang01.github.io/">this fellow</a>.
        </p>-->
        <p align=center>
          <a href="mailto:removethisifyouarehuman-ruthfong@princeton.edu">Email</a> |
          <a href="files/ruth_fong_cv.pdf">CV</a> |
          <a href="files/ruth_fong_bio.txt">Bio</a> |
          <!--<a href="files/ruth_fong_bio.txt">Biography</a> &nbsp/&nbsp-->
          <a href="https://scholar.google.com/citations?user=39cUD3gAAAAJ">Google Scholar</a> |
          <a href="https://github.com/ruthcfong">GitHub</a>
          <!--<a href="http://www.linkedin.com/in/jonathanbarron/"> LinkedIn </a>-->
        </p>
        </td>
        <td width="33%">
          <img src="media/color_headshot_v2.png" width="250" alt="headshot">
          <!--<div class="one">
          <div class="two" id="headshot_image"><img src="media/color_headshot.png" width="250" alt="headshot"></div>
          <img src="media/bw_headshot.png" width="250" alt="headshot">
          </div>
          <script type="text/javascript">
          function headshot_start() {
          document.getElementById('headshot_image').style.opacity = "1";
          }
          function headshot_stop() {
          document.getElementById('headshot_image').style.opacity = "0";
          }
          filters_stop()
          </script>-->
        </td>
        <!--<td width="33%">
        <img src="media/bw_headshot.png" width="250">
        <img src="media/color_headshot.png" width="250">
        </td>-->
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr width="100%" valign="middle">
        <td>
        <heading>Hello! &#128075;</heading>
          <p>
          I am excited to work with Princeton students! If you are a...
          </p>
          <ul>
            <li><b>Princeton undergraduate student</b> interested in doing an IW, a senior thesis, and/or research with me, please first read my <a href="https://www.cs.princeton.edu/ugrad/independent-work/undergraduate-research-topics#Fong">preferred list</a> of IW topics. If one of the topics interests you, please email me your (1) CV, (2) transcript, and (3) a short description of what you might be interested in working on (I also have a few project ideas I can suggest). I recommend you first (or currently) take COS429 (or at least COS324) before working with me. I am particularly excited about helping students from <b>underrepresented groups</b> have a positive and successful first research experience. 
            <li><b>Princeton graduate student</b> interested in working or collaborating with me, please reach out via email.
            </li>
            <li><b>non-Princeton student</b> (including prospective applicants) interested in working with me, there's no need to email; I unfortunately am not accepting non-Princeton students at this time.
            </li>
          </ul>
        </td>
      </tr>
      <tr>
        <td>
          <heading>News &#128478;</heading>
            <ul>
              <li><b>Along with my co-editors, our book on "xxAI - Beyond Explainable AI" is now available: <a href="https://link.springer.com/book/10.1007/978-3-031-04083-2">link</a></b></li>
              <li>Along with my co-instructors, I introduced an open-ended final project to <a href="https://www.cs.princeton.edu/~cos126">COS126</a> (i.e. Princeton's intro CS course), here's the <a href="https://www.cs.princeton.edu/courses/archive/spr22/cos126/gallery/">online gallery</a> of the amazing projects students created!</li>
              <li>I am excited to announce that I am joining <a href="https://www.cs.princeton.edu/">Princeton's CS</a> department as a teaching faculty member starting July 2021.</li>
              <li>My PhD thesis on "Understanding Convolutional Neural Networks" can be found <a href="files/fong20_thesis.pdf">here</a>. For those with less experience, all chapters except chapters 3-6 were written with accessibility in mind.</li>
              <li>We have a new report out on "Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims." <a href="http://www.towardtrustworthyai.com/">webpage</a> | <a href="https://arxiv.org/abs/2004.07213">arXiv</a>
              <li>We just released <a href="https://github.com/facebookresearch/TorchRay">TorchRay</a>, a PyTorch interpretability library. In the initial release, we focus on attribution and re-implemented popular methods and benchmarks to encourage reproducible research. Resources:
              	<a href="http://ruthcfong.github.io/files/fong19_torchray_tutorial.pdf">tutorial slides</a> | 
              	<a href="https://bit.ly/torchray_colab_tutorial">colab notebook</a></li> 
              <!--
              <li>In summer 2019, I worked part-time as a contractor with Pro Unlimited for Facebook AI Research (FAIR) London.</li>
              <li>In 2018, I was awarded an <a href="https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/announcing-2018-ai-fellows">Open Philanthropy AI Fellowship</a>. I explain some of my research aspirations in <a href="http://www.eng.ox.ac.uk/about/news/engineering-science-students-selected-as-ai-fellows">this departmental announcement</a>.
              <li>In summer 2018, I interned at <a href="https://research.google.com/">Google Research</a> in Zurich and worked with Vitto Ferrari's LOCO team.
              <li>At ICCV 2017, I gave a contributing talk at the <a href="https://sites.google.com/site/mbcc2017w/home">Mutual Benefits of Cognitive and Computer Vision</a> workshop (<a href="files/fong_iccv17_mbcc_talk_using_human_brain_activity.pdf">slides</a>).</li>
              <li>In summer 2017, I won the Best Poster Award at the <a href="http://iplab.dmi.unict.it/icvss/">International Computer Vision Summer School (ICVSS)</a>.</li>
              <li>In spring 2017, New Scientist wrote an <a href="https://www.newscientist.com/article/mg23431192-500-mri-brain-scans-train-machines-to-see-the-world-more-like-us/">article</a> about my work with David Cox and Walter Scheirer.</li>
              -->
            </ul>
        </td>
      </tr>
      <tr>
        <td>
          <heading>Talks &#x1F469;&#x1F3FB;&#x200D;&#x1F3EB;</heading>
          <ul>
            <li><b>HEIBRiDS Lecture Series 2022 &#8212  "Directions in Interpretability":</b> <a href="./files/fong_2022-11-16-cvpr22_heibrids_lecture.pdf">slides</a> | <a href="https://www.heibrids.berlin/events-training/lecture-series/">series webpage</a></li>
            <li>MICCAI 2022 &#8212 "Directions in Interpretability" at the iMIMIC workshop (Interpretability of Machine Intelligence in Medical Image Computing): <a href="./files/fong_2022-09-22-miccai22_workshop_lowquality.pdf">slides</a> | <a href="https://imimic-workshop.com/">workshop webpage</a></li>
            <li>CVPR 2022 &#8212 "Directions in Interpretability" at the Human-Centered AI for Computer Vision tutorial: <a href="https://www.youtube.com/watch?v=mBEqoIpfqFc">video</a> | <a href="./files/fong_2022-06-20-cvpr22_hcai_tutorial-draft-low-quality.pdf">slides</a> | <a href="https://human-centeredai.github.io/">tutorial webpage</a></li>
            <li>CVPR 2020 &#8212 "Understanding Deep Neural Networks" at the Interpretable Machine Learning for Computer Vision tutorial: <a href="https://youtu.be/YrlWq0oFZ50">video<a> | <a href="https://interpretablevision.github.io/slide/cvpr20_ruth.pdf">slides</a> | <a href="https://interpretablevision.github.io/index_cvpr2020.html">tutorial webpage</a></li>
            <li>Oxford VGG 2019 &#8212 Interpretability tutorial: <a href="http://ruthcfong.github.io/files/fong19_interpretability_vgg_tutorial_slides.pdf">slides</a>

          </ul>
        </td>
      </tr>

      <tr>
        <td width="100%" valign="middle" margin="auto">
        <heading>Looking Glass Lab &#128100</heading>
        <h3>Members</h3>
        <!--
          Undergrads:
          Frelicia,
          Indu,
          Alexis,
          Creston,
          Devon,
          Vedant,
          Nicole,
          Vikram,
          Sunnie,
          Angelina,
          Olga,
        -->
        <!--<h3>Undergrad Students</h3>-->
        <!--

          "Alice in Wonderland Flower" by Sam Howzit is licensed under CC BY-NC-ND 2.0. 
          "NYC - Central Park: Alice in Wonderland - White Rabbit" by wallyg is licensed under CC BY 2.0
          "NYC - Central Park: Alice in Wonderland - Mad Hatter" by wallyg is licensed under CC BY-NC-ND 2.0
          "alice in wonderland + ibrahim el-salahi" by Gene Kogan is licensed under CC BY-NC-SA 2.0
          "alice in wonderland + elaine de kooning" by Gene Kogan is licensed under CC BY-NC-SA 2.0
          chester cat: https://flic.kr/p/8Docr7
          chester cat bw: public domain https://publicdomainvectors.org/en/free-clipart/Cheshire-cat-from-Alice-in-wonderland/71524.html
          white bunny bw: public domain https://publicdomainvectors.org/en/free-clipart/The-white-bunny/54087.html
          big shrimp bw: public domain https://publicdomainvectors.org/en/free-clipart/Big-shrimp/63480.html
          mad hatter bw: public domain https://publicdomainvectors.org/en/free-clipart/Alice-in-Wonderland-character/63485.html
          alice bw: public domain https://publicdomainvectors.org/en/free-clipart/Storybook-Alice/63487.html
          alice and catepillar bw: public domain https://publicdomainvectors.org/en/free-clipart/Alice-and-the-caterpillar/81786.html
          larspur_stenzel: https://www.flickr.com/photos/peterstenzel/51258950867

          larspur_wiki: https://commons.wikimedia.org/wiki/File:Larkspur_Delphinium_glaucum_closeup.jpg
          orange_tiger_lily_wiki: https://commons.wikimedia.org/wiki/File:Orange_Tiger_Lily.jpg
          https://aliceinwonderland.fandom.com/wiki/The_Flowers
          daisy_wiki: https://commons.wikimedia.org/wiki/File:Daisy_(49234484218).jpg
          voilet_wiki: https://commons.wikimedia.org/wiki/File:Alpine_Violet_Viola_labradorica_Flower_1453px.jpg
          pink_rose_wiki: https://commons.wikimedia.org/wiki/File:Pink_rose_.JPG
          red_rose_wiki: https://commons.wikimedia.org/wiki/File:Rose_Osaka.JPG
          white_iris_wiki: https://commons.wikimedia.org/wiki/File:Iris_ensata_Thunb.jpg
          light_purple_iris_wiki: https://commons.wikimedia.org/wiki/File:Iris_douglasiana_flower_2003-03-17.jpg
        -->
        <p class="people">
          <a href="https://www.linkedin.com/in/icey-siyi-ai/">
            <img src="media/icey_ai.jpg">
            Icey Siyi Ai
          </a>
          <a href="https://www.linkedin.com/in/fatima-zohra-boumhaout-5a1707225">
            <img src="media/zohra_boumhaout.jpeg">
            Fatima Zohra Boumhaout
          </a>
          <a href="">
            <img src="media/orange_tiger_lily_wiki.jpeg">
            Creston Brooks
          </a>
          <a href="">
            <img src="media/indu_panigrahi.jpeg">
            Indu Panigrahi
          </a>
          <a href="https://www.linkedin.com/in/sursock/">
            <img src="media/alexis_sursock.png">
            Alexis Sursock
          </a>
          <!--<a href="">
            <img src="media/frelicia_tucker.jpg">
            Frelicia Tucker
          </a>-->
          <a href="https://github.com/devonulrich">
            <!--<img style="object-fit: contain;"src="media/alice_in_wonderland_chester_cat_bw.png">-->
            <img src="media/devon_ulrich.jpg">
            Devon Ulrich
          </a>
          <!--<a href="">
            <img src="media/vedant_dhopte.jpg">
            Dhopte Vedant
          </a>-->
        </p>
        <h3>Collaborators</h3>
        <p class="people">
          <a href="https://nicolemeister.github.io/">
            <img src="media/nicole_meister.jpeg">
            Nicole Meister
          </a>
          <a href="https://dorazhao99.github.io/">
            <img src="media/dorothy_zhao.jpeg">
            Dora Zhao 
          </a>
          <a href="https://sunniesuhyoung.github.io/">
            <img src="media/sunnie_kim.jpeg">
            Sunnie S. Y. Kim
          </a>
          <a href="https://rmanzuk.mycpanel.princeton.edu/">
            <img src="media/ryan_manzuk.jpeg">
            Ryan Manzuk
          </a>
          <a href="https://www.cs.princeton.edu/~vr23/">
            <img src="media/vikram_ramaswamy.jpeg">
            Vikram V. Ramaswamy
          </a>
          <a href="https://angelina-wang.github.io/">
            <img src="media/angelina_wang.png">
            Angelina Wang
          </a>

          <a href="https://cargocollective.com/ElizabethAnneWatkins">
            <img src="media/elizabeth_anne_watkins.jpg">
            Dr. Elizabeth Anne Watkins 
          </a>

          <a href="http://cs.princeton.edu/~olgarus">
            <img src="media/olga_russakovsky.jpeg">
            Prof. Olga Russakovsky 
          </a>
          <a href="https://www.andresmh.com/">
            <img src="media/andres_monroy_hernandez_2.jpg">
            Prof. Andr&eacute;s Monroy-Hern&aacute;ndez
          </a>
          <a href="https://geosciences.princeton.edu/people/adam-c-maloof">
            <img src="media/adam_maloof_cropped.jpg">
            Prof. Adam C. Maloof
          </a>
        </p>
        <p style="text-align:right">
        [<a href="files/collaborators_image_attribution.txt"><i>image attribution</i></a>]
        </p>
        <h3>Alumni</h3>
        <ul>
          <li>Frelicia Tucker '22, senior thesis, The Virtual Black Hair Experience: Evaluating Hairstyle Transform Generative Adversarial Networks on Black Women.</li>
          <li>Vedant Dhopte '22, senior thesis, Holistically Interpreting Deep Neural Networks via Channel Ablation.</li>
        </ul>
        </td>
      </tr>
      <!--
      <tr>
        <td width="100%" valign="middle">
          <heading>Collaborators &#128100</heading>
          <p></p>
          <table>
            <tr>
              <td width="20%" valign="middle" style="">
                <div style="align:center;">
                <img src="media/color_headshot_v2.png" width="100%" style="margin:0 auto;" alt="headshot">
                <p style="text-align: center">Ruth Fong</p>
                </div>
              </td>
              <td width="20%" valign="middle" style="">
                <img src="media/color_headshot_v2.png" width="100%" style="margin:0 auto;" alt="headshot">
                <p>Ruth Fong</p>
              </td>
              <td width="20%" valign="middle" style="margin:10px;">
                <img src="media/color_headshot_v2.png" width="100%" alt="headshot">
                <p>Ruth Fong</p>
              </td>
              <td width="20%" valign="middle" style="margin:10px;">
                <img src="media/color_headshot_v2.png" width="100%" alt="headshot">
                <p>Ruth Fong</p>
              </td>
              <td width="20%" valign="middle" style="margin:10px;">
                <img src="media/color_headshot_v2.png" width="100%" alt="headshot">
                <p>Ruth Fong</p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
      -->

      <tr>
        <td width="100%" valign="middle">
          <heading>Research &#129514</heading>
          <p>
          My research interests are in computer vision, machine learning, deep learning, and explainable AI.
          I am interested in developing novel techniques for understanding AI models <i>post-hoc</i>, designing new deep learning archiectures that are <i>interpretable-by-design</i>, and introducing paradigms for <i>finding and correcting</i> existing failure points in AI models. 
          See <a href="https://scholar.google.com/citations?user=39cUD3gAAAAJ">Google Scholar</a> for the most updated list of papers.

          <!-- Representative papers are <span class="highlight">highlighted</span>; see <a href="https://scholar.google.com/citations?user=39cUD3gAAAAJ">Google Scholar</a> for the most updated list of papers. -->

          <!--I am excited about Much of my current research is about explaining what deep neural networks are actually learning (i.e., where does an image classifier "look" in an image for evidence for its predicted class?, how are human-interpretable concepts encoded across CNN filters?, how do CNN representations compare to those learned by mammalian visual systems?). Representative papers are <span class="highlight">highlighted</span>.-->
          </p>
        </td>
      </tr>

      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tr> <!--onmouseout="sim_stop()" onmouseover="sim_start()"> -->
      <!-- <tr class="highlight">  -->
      <td width="25%">
        <img src="./media/fossil.png" alt="fossil image"  width="160" id="fossil_one">
      </td>
      <td valign="top" width="75%">
        <a href="https://arxiv.org/pdf/2210.03879.pdf">
          <papertitle>
            Improving Fine-Grain Segmentation via Interpretable Modifications: A Case Study in Fossil Segmentation
          </papertitle>
        </a>
        <br>
          <a href="">Indu Panigrahi</a>, 
          <a href="https://rmanzuk.mycpanel.princeton.edu/">Ryan Manzuk</a>, 
          <a href="https://geosciences.princeton.edu/people/adam-c-maloof">Adam Maloof</a>, 
          <strong>Ruth Fong</strong>
        <br>
        <em>arXiv</em>, 2022&nbsp; 
        <br>
        <a href="https://arxiv.org/abs/2210.03879">arXiv</a> | 
        <a href="./bib/PanigrahiArXiv2022.bib">bibtex</a>
        <p>
          We explore how to improve a model for segmenting coral reef fossils by first understanding its systematic failures and second ``editing'' the model to mitigate said failures.
        </p>
      </td>
    </tr>


    <tr class="highlight">
      <td width="25%">
        <img src='media/merlin_wren.png' width="160">
      </td>
      </td>
      <td valign="top" width="75%">
        <a href="https://arxiv.org/pdf/2210.03735.pdf" target="_blank">
          <papertitle>"Help Me Help the AI": Understanding How Explainability Can Support Human-AI Interaction</papertitle>
        </a>
        <br>
        <a href="https://sunniesuhyoung.github.io">Sunnie S. Y. Kim</a>,
        <a href="http://www.ElizabethAnneWatkins.com">Elizabeth Anne Watkins</a>,
        <a href="https://www.cs.princeton.edu/~olgarus/">Olga Russakovsky</a>,
        <strong>Ruth Fong</strong>,
        <a href="https://www.andresmh.com/">Andr&eacute;s Monroy-Hern&aacute;ndez</a>
        <br>
        <em>arXiv, 2022</em>
        <br>
        <a href="https://arxiv.org/abs/2210.03735">arXiv</a> |
        <a href="bib/KimArXiv2022.bib">bibtex</a>
        <p></p>
        <p>
          We explore how explainability can support human-AI interaction by interviewing 20 end-users of a real-world AI application. 
          Specifically, we study (1) what XAI needs people have, (2) how people intend to use XAI explanations, and (3) how people perceive existing XAI methods.
        <p>
      </td>
    </tr>

    <tr class="highlight"> <!--onmouseout="sim_stop()" onmouseover="sim_start()"> -->
      <!-- <tr class="highlight">  -->
      <td width="25%">
        <img src="./media/overlooked_factors.png" alt="ELUDE image"  width="160" id="elude_one">
      </td>
      <td valign="top" width="75%">
        <a href="https://arxiv.org/pdf/2207.09615.pdf">
          <papertitle>
            Overlooked Factors in Concept-based Explanations: Dataset Choice, Concept Salience, and Human Capability
          </papertitle>
        </a>
        <br>
          <a href="https://www.cs.princeton.edu/~vr23/">Vikram V. Ramaswamy</a>, 
          <a href="https://cs.princeton.edu/~suhk">Sunnie S. Y. Kim</a>, 
          <strong>Ruth Fong</strong>, 
          <a href="http://cs.princeton.edu/~olgarus/">Olga Russakovsky</a>
        <br>
        <em>arXiv</em>, 2022&nbsp; 
        <br>
        <a href="https://arxiv.org/abs/2207.09615">arXiv</a> | 
        <a href="./bib/Ramaswamy2ArXiv2022.bib">bibtex</a>
        <p>
          We analyze three commonly overlooked factors in concept-based explanations, (1) the choice of the probe dataset, (2) the saliency of concepts in the probe dataset, (3) the number of concepts used in explanations, and make suggestions for future development and analysis of concept-based interpretability methods.
        </p>
      </td>
    </tr>


      <tr class="highlight" onmouseout="search_stop()" onmouseover="search_start()">
      <td width="25%">
        <!--<img src="./media/gdt.png" alt="hierarchical transformations" width="160" height="160">-->
        <div class="one">
        <div class="two" id="search_two" style="display:table-cell; vertical-align:middle; text-align:center;opacity:0;">
          <img src="./media/spia_highlighting.gif" alt="animated gif of interactive search"  width="160">
        </div>
        <img src="./media/spia_first_frame.png" alt="static image of interactive search"  width="160" id="search_one">
        </div>
        <script type="text/javascript">
        function search_start() {
        document.getElementById('search_two').style.opacity = "1";
        }
        function search_stop() {
        document.getElementById('search_two').style.opacity = "0";
        }
        search_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <a href="https://arxiv.org/pdf/2211.15060.pdf">
          <papertitle>Interactive Visual Feature Search</papertitle>
        </a>
        <br>
          <a href="https://github.com/devonulrich">Devon Ulrich</a> and  
          <strong>Ruth Fong</strong>
        <br>
        <em>arXiv</em>, 2022&nbsp; 
        <br>
        <a href="https://arxiv.org/abs/2211.15060">arXiv</a> | 
        <a href="https://github.com/lookingglasslab/VisualFeatureSearch">code</a> | 
        <a href="./bib/UlrichArXiv2022.bib">bibtex</a>
        <p>
          We present an interactive visualization tool that allows you to perform a reverse image search for similar image regions using intermediate activations.
        </p>
      </td>
    </tr>

      <tr class="highlight" onmouseout="artifacts_stop()" onmouseover="artifacts_start()">
      <td width="25%">
        <!--<img src="./media/gdt.png" alt="hierarchical transformations" width="160" height="160">-->
        <div class="one">
        <div class="two" id="artifacts_two" style="display:table-cell; vertical-align:middle; text-align:center;opacity:0;">
          <img src="./media/artifacts_pose.png" alt="difference in avg pose between labelled female and male images"  width="160">
        </div>
        <img src="./media/artifacts_color.png" alt="difference in avg color between labelled female and male images"  width="160" id="artifacts_one">
        </div>
        <script type="text/javascript">
        function artifacts_start() {
        document.getElementById('artifacts_two').style.opacity = "1";
        }
        function artifacts_stop() {
        document.getElementById('artifacts_two').style.opacity = "0";
        }
        search_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <a href="https://arxiv.org/pdf/2206.09191.pdf">
          <papertitle>
            Gender Artifacts in Visual Datasets
          </papertitle>
        </a>
        <br>
          <a href="https://nicolemeister.github.io/">Nicole Meister*</a>, 
          <a href="https://dorazhao99.github.io/">Dora Zhao*</a>, 
          <a href="https://angelina-wang.github.io/">Angelina Wang</a>, 
          <a href="https://www.cs.princeton.edu/~vr23/">Vikram V. Ramaswamy</a>, 
          <strong>Ruth Fong</strong>, 
          <a href="http://cs.princeton.edu/~olgarus/">Olga Russakovsky</a>
        <br>
        <em>arXiv</em>, 2022&nbsp; 
        <br>
        <a href="https://arxiv.org/abs/2206.09191">arXiv</a> | 
        <a href="https://princetonvisualai.github.io/gender-artifacts/">project page</a> | 
        <a href="./bib/MeisterArXiv2022.bib">bibtex</a>
        <p>
          We demonstrate the pervasive-ness of gender artifacts in popular computer vision datasets (e.g. COCO and OpenImages). We find that all of the following (and more) are gender artifacts: the mean value of color channels (i.e. mean RGB), the pose and location of people, and most co-located objects. 
        </p>
      </td>
    </tr>



    <tr class="highlight"> <!--onmouseout="sim_stop()" onmouseover="sim_start()"> -->
      <!-- <tr class="highlight">  -->
      <td width="25%">
        <img src="./media/ELUDE2022_simple.png" alt="ELUDE image"  width="160" id="elude_one">
      </td>
      <td valign="top" width="75%">
        <a href="https://arxiv.org/pdf/2206.07690.pdf">
          <papertitle>ELUDE: Generating Interpretable Explanations via a Decomposition into Labelled and Unlabelled Features</papertitle>
        </a>
        <br>
          <a href="https://www.cs.princeton.edu/~vr23/">Vikram V. Ramaswamy</a>, 
          <a href="https://cs.princeton.edu/~suhk">Sunnie S. Y. Kim</a>, 
          <a href="https://nicolemeister.github.io/">Nicole Meister</a>, 
          <strong>Ruth Fong</strong>, 
          <a href="http://cs.princeton.edu/~olgarus/">Olga Russakovsky</a>
        <br>
        <em>arXiv</em>, 2022&nbsp; 
        <br>
        <a href="https://arxiv.org/abs/2206.07690">arXiv</a> | 
        <a href="./bib/RamaswamyArXiv2022.bib">bibtex</a>
        <p>
          We present ELUDE, a novel explanation framework that decomposes a model's prediction into two components: 1. using labelled, semantic attributes (e.g. fur, paw, etc.) and 2. using an unlabelled, low-rank feature space.
        </p>
      </td>
    </tr>

    <tr class="highlight"> <!--onmouseout="sim_stop()" onmouseover="sim_start()"> -->
      <td width="25%">
        <!--<img src="./media/gdt.png" alt="hierarchical transformations" width="160" height="160">-->
        <!--<div class="one">
        <div class="two" id="sim_two" style="display:table-cell; vertical-align:middle; text-align:center;opacity:0;">
          <img src="./media/interactive_sim_2.png" alt="interactive similarity example #2"  width="160">
        </div>
        <img src="./media/interactive_sim_1.png" alt="interactive similarity example #1"  width="160" id="sim_one">
        </div>
      -->
        <img src="./media/HIVE2021.png" alt="HIVE image"  width="160" id="hive_one">
        <!--<script type="text/javascript">
        function sim_start() {
        document.getElementById('sim_two').style.opacity = "1";
        }
        function sim_stop() {
        document.getElementById('sim_two').style.opacity = "0";
        }
        splash_stop()
        </script>-->
      </td>
      <td valign="top" width="75%">
        <a href="https://arxiv.org/pdf/2112.03184.pdf">
          <papertitle>HIVE: Evaluating the Human Interpretability of Visual Explanations</papertitle>
        </a>
        <br>
          <a href="https://cs.princeton.edu/~suhk">Sunnie S. Y. Kim</a>, 
          <a href="https://nicolemeister.github.io/">Nicole Meister</a>, 
          <a href="https://www.cs.princeton.edu/~vr23/">Vikram V. Ramaswamy</a>, 
          <strong>Ruth Fong</strong>, 
          <a href="http://cs.princeton.edu/~olgarus/">Olga Russakovsky</a>
        <br>
        <em>ECCV</em>, 2022&nbsp; 
        <br>
        <a href="https://arxiv.org/abs/2112.03184">arXiv</a> | 
        <a href="https://princetonvisualai.github.io/HIVE/">project page</a> | 
        <a href="https://drive.google.com/file/d/1nOYfy_0e61cGGDzwreCI4IUly1VbTgur/view?usp=sharing">extended abstract</a> |
        <a href="https://github.com/princetonvisualai/HIVE">code</a> | 
        <a href="https://youtu.be/BDlFb1CFQRQ">2-min video</a> |
        <a href="./bib/KimECCV2022.bib">bibtex</a>
        <p>
          We introduce HIVE, a novel human evaluation framework for diverse interpretability methods in computer vision, and develop metrics that measure achievement on two desiderata for explanations used to assist human decision making: (1) Explanations should allow users to distinguish between correct and incorrect predictions. (2) Explanations should be understandable to users.
        </p>
      </td>
    </tr>

    <tr class="highlight" onmouseout="sim_stop()" onmouseover="sim_start()">
      <td width="25%">
        <!--<img src="./media/gdt.png" alt="hierarchical transformations" width="160" height="160">-->
        <div class="one">
        <div class="two" id="sim_two" style="display:table-cell; vertical-align:middle; text-align:center;opacity:0;">
          <img src="./media/interactive_sim_2.png" alt="interactive similarity example #2"  width="160">
        </div>
        <img src="./media/interactive_sim_1.png" alt="interactive similarity example #1"  width="160" id="sim_one">
        </div>
        <script type="text/javascript">
        function sim_start() {
        document.getElementById('sim_two').style.opacity = "1";
        }
        function sim_stop() {
        document.getElementById('sim_two').style.opacity = "0";
        }
        splash_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <a href="https://ruthcfong.github.io/projects/interactive_overlay/">
          <papertitle>Interactive Similarity Overlays</papertitle>
        </a>
        <br>
          <strong>Ruth Fong</strong>, 
          <a href="https://znah.net/">Alexander Mordvintsev</a>, 
          <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>, 
          <a href="https://colah.github.io/">Chris Olah</a>
        <br>
        <em>VISxAI</em>, 2021&nbsp; 
        <br>
        <a href="https://ruthcfong.github.io/projects/interactive_overlay/">interactive article </a> | 
        <a href="https://github.com/ruthcfong/interactive_overlay">code</a> | 
        <a href="./bib/FongVISxAI2021.bib">bibtex</a>
        <p>
          We introduce a novel interactive visualization that allows machine learning practitioners and researchers to easily observe, explore, and compare how a neural network perceives different image regions.
        </p>
      </td>
    </tr>

    <tr><!-- onmouseout="splash_stop()" onmouseover="splash_start()">-->
      <td width="25%">
        <img src="./media/gdt.png" alt="hierarchical transformations" width="160" height="160">
        <!--<div class="one">
        <div class="two" id="splash_gif"><img src='media/splash.gif' width="160" height="160"></div>
        <img src='media/normgrad_test.png' width="160" height="160">
        </div>
        <script type="text/javascript">
        function splash_start() {
        document.getElementById('splash_gif').style.opacity = "1";
        }
        function splash_stop() {
        document.getElementById('splash_gif').style.opacity = "0";
        }
        splash_stop()
        </script>-->
      </td>
      <td valign="top" width="75%">
        <a href="https://arxiv.org/pdf/2003.04298.pdf">
          <papertitle>On Compositions of Transformations in Contrastive Self-Supervised Learning</papertitle>
        </a>
        <br>
          <a href="https://www.linkedin.com/in/mandelapatrick/">Mandela Patrick*</a>,
          <a href="https://yukimasano.github.io/">Yuki M. Asano*</a>,
          <a href="https://scholar.google.com/citations?user=JdEJEicAAAAJ&amp;hl=en&amp;oi=ao">Polina Kuznetsova</a>,
          <strong>Ruth Fong</strong>,
          <a href="http://www.robots.ox.ac.uk/~joao/">Jo&#227;o F. Henriques</a>,
          <a href="https://www.linkedin.com/in/geoffreyzweig">Geoffrey Zweig</a>, and 
          <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>
        <br>
        <em>ICCV</em>, 2021&nbsp; 
        <br>
        <a href="https://arxiv.org/abs/2003.04298">arXiv</a> | 
        <a href="https://github.com/facebookresearch/GDT">code</a> |
        <a href="./bib/PatrickICCV2021.bib">bibtex</a>
        <p>
          We give transformations the prominence they deserve by introducing a systematic framework suitable for contrastive learning. SOTA video representation learning by learning (in)variances systematically.
        </p>
      </td>
    </tr>


    <tr class="highlight" onmouseout="describability_stop()" onmouseover="describability_start()">
      <td width="25%">
        <!--<img src="./media/describability_1.png" alt="describability metric diagram"  width="160">-->
        <div class="one">
        <div class="two" id="describability_two" style="display:table-cell; vertical-align:middle; text-align:center;">
          <img src="./media/describability_2.png" alt="describability metric diagram"  width="140">
        </div>
        <img src="./media/describability_1.png" alt="describability metric diagram"  width="160" id="describability_one">
        </div>
        <script type="text/javascript">
        function describability_start() {
        document.getElementById('describability_one').style.opacity = "0";
        document.getElementById('describability_two').style.opacity = "1";
        }
        function describability_stop() {
        document.getElementById('describability_two').style.opacity = "0";
        document.getElementById('describability_one').style.opacity = "1";
        }
        describability_stop();
        </script>
      </td>
      <td valign="top" width="75%">
            <a href="https://arxiv.org/pdf/2010.14551.pdf">
              <papertitle>Quantifying Learnability and Describability of Visual Concepts Emerging in Representation Learning</papertitle>
            </a>
      <br>
          <a href="http://campar.in.tum.de/Main/IroLaina">Iro Laina</a>, 
          <strong>Ruth Fong</strong>, and
          <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>
          
      <br>
        <em>NeurIPS</em>, 2020
      <br>
        <a href="https://arxiv.org/abs/2010.14551">arxiv</a> | 
        <a href="https://proceedings.neurips.cc/paper/2020/file/98dce83da57b0395e163467c9dae521b-Supplemental.pdf">supp</a> | 
        <a href="bib/LainaNeurIPS2020.bib" target="_blank">bibtex</a>
        <p></p>
        <p>We introduce two novel human evaluation metrics for quantifying for evaluating the interpretability of clusters discovered via self-supervised methods. We also outline how to partially approximate one of the metrics using a group captioning model.
        </p>
      </td>
    </tr>


    <tr onmouseout="debiasing_stop()" onmouseover="debiasing_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="debiasing_two">
          <img src='media/debiasing_2.png' width="160">
        </div>
        <img src='media/debiasing_1.png' width="160">
        </div>
        <script type="text/javascript">
        function debiasing_start() {
        document.getElementById('debiasing_two').style.opacity = "1";
        }
        function debiasing_stop() {
        document.getElementById('debiasing_two').style.opacity = "0";
        }
        debiasing_stop()
        </script>
      </td>
      <td valign="top" width="75%">
            <a href="https://arxiv.org/pdf/2011.07453.pdf">
              <papertitle>Debiasing Convolutional Neural Networks via Meta Orthogonalization</papertitle>
            </a>
      <br>
          <a href="https://kurtisdavid.github.io/">Kurtis Evan David</a>,
          <a href="https://www.cs.utexas.edu/~lqiang/">Qiang Liu</a>, and
          <strong>Ruth Fong</strong>
      <br>
        <em>NeurIPS Workshop on Algorithmic Fairness through the Lens of Causality and Interpretability (AFCI)</em>, 2020
      <br>
        <a href="https://arxiv.org/abs/2011.07453">arxiv</a> | 
        <a href="http://ruthcfong.github.io/files/david20_debiasing_supps.pdf">supp</a> | 
        <a href="http://ruthcfong.github.io/files/david20_debiasing_poster.pdf">poster </a> | 
        <a href="bib/DavidNeurIPSW2020.bib" target="_blank">bibtex</a>
        <p></p>
        <p>We introduce a novel paradigm for debiasing CNNs by encouraging salient concept vectors to orthogonal to class vectors in the activation space of an intermediate CNN layer (e.g., orthogonalizing gender and oven concepts in conv5).
        </p>
      </td>
    </tr>


    <tr onmouseout="contextual_stop()" onmouseover="contextual_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="contextual_two"><img src='media/contextual_2.png' height="160"></div>
        <img src='media/contextual_1.png' height="160">
        </div>
        <script type="text/javascript">
        function contextual_start() {
        document.getElementById('contextual_two').style.opacity = "1";
        }
        function contextual_stop() {
        document.getElementById('contextual_two').style.opacity = "0";
        }
        contextual_stop()
        </script>
      </td>
      <td valign="top" width="75%">
            <a href="https://openaccess.thecvf.com/content/ACCV2020/papers/Marcos_Contextual_Semantic_Interpretability_ACCV_2020_paper.pdf">
              <papertitle>Contextual Semantic Interpretability</papertitle>
            </a>
      <br>
          <a href="https://scholar.google.ch/citations?user=IUqydU0AAAAJ&hl=en">Diego Marcos</a>,
          <strong>Ruth Fong</strong>,
          <a href="https://www.sylvainlobry.com/">Sylvain Lobry</a>,
          <a href="https://remi.flamary.com/">R&eacute;mi Flamary</a>,
          <a href="https://people.irisa.fr/Nicolas.Courty/">Nicolas Courty</a>, and
          <a href="https://sites.google.com/site/devistuia/">Devis Tuia</a>
      <br>
        <em>ACCV</em>, 2020
      <br>
        <a href="https://arxiv.org/abs/2009.08720">arxiv</a> | 
        <a href="https://openaccess.thecvf.com/content/ACCV2020/supplemental/Marcos_Contextual_Semantic_Interpretability_ACCV_2020_supplemental.pdf">supp</a> | 
        <a href="https://github.com/dmarcosg/CSIB">code</a> | 
        <a href="bib/MarcosACCV2020.bib" target="_blank">bibtex</a>
        <p></p>
        <p>We introduce an interpretable-by-design machine vision model that learns to sparse groupings of interpretable concepts and demonstrate the utility of our novel architecture on scenicness prediction.
        </p>
      </td>
    </tr>



    <tr onmouseout="splash_stop()" onmouseover="splash_start()">
      <td width="25%">
        <!--<div class="one">
        <div class="two" id="tripod_image"><img src="media/tripod_2.png" width="160" height="160" alt="tripod"></div>
        <img src="media/tripod_1.png" width="160" height="160" alt="tripod">-->
        <div class="one">
        <div class="two" id="splash_gif"><img src='media/splash.gif' width="160" height="160"></div>
        <img src='media/normgrad_test.png' width="160" height="160">
        </div>
        <script type="text/javascript">
        function splash_start() {
        document.getElementById('splash_gif').style.opacity = "1";
        }
        function splash_stop() {
        document.getElementById('splash_gif').style.opacity = "0";
        }
        splash_stop()
        </script>

        <!--<script type="text/javascript">
        function tripod_start() {
        document.getElementById('tripod_image').style.opacity = "1";
        }
        function tripod_stop() {
        document.getElementById('tripod_image').style.opacity = "0";
        }
        tripod_stop()
        </script>-->
      </td>
      <td valign="top" width="75%">
            <a href="https://arxiv.org/abs/2004.02866">
              <papertitle>There and Back Again: Revisiting Backpropagation Saliency Methods</papertitle>
            </a>
      <br>
          <a href="https://www.robots.ox.ac.uk/~srebuffi/">Sylvestre-Alvise Rebuffi*</a>,
          <strong>Ruth Fong*</strong>,
          <a href="https://scholar.google.co.uk/citations?user=HQzOgKYAAAAJ&hl=en">Xu Ji*</a>, and
          <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>
      <br>
        <em>CVPR</em>, 2020
      <br>
        <a href="https://arxiv.org/abs/2004.02866">arxiv</a> | 
        <a href="https://github.com/srebuffi/revisiting_saliency">code</a> | 
        <a href="bib/RebuffiCVPR2020.bib" target="_blank">bibtex</a>
        <div style="display: none;" id="cvpr20_bib">
          <pre>
@InProceedings{rebuffi_cvpr_2020,
author = {Rebuffi, Sylvestre-Alvise and Fong, Ruth and Ji, Xu and Vedaldi, Andrea},
title = {There and Back Again: Revisiting Backpropagation Saliency Methods},
booktitle = {The IEEE Conference on Computer Vision 
  and Pattern Recognition (CVPR)},
year = {2020}
}
          </pre>
        </div>
        <p></p>
        <p>We outline a novel framework that unifies many backpropagation saliency methods. Furthermore, we introduce NormGrad, a saliency method that considers the spatial contribution of the gradients of convolutional weights. We also systematically study the effects of combining saliency maps at different layers. Finally, we introduce a class-sensitivity metric and a meta-learning inspired technique that can be applied to any saliency method to improve class sensitivity.
        </p>
      </td>
    </tr>

    <tr><!-- onmouseout="splash_stop()" onmouseover="splash_start()">-->
      <td width="25%">
        <img src="media/trustworthy_screenshot.png" width="160">
        <!--<div class="one">
        <div class="two" id="splash_gif"><img src='media/splash.gif' width="160" height="160"></div>
        <img src='media/normgrad_test.png' width="160" height="160">
        </div>
        <script type="text/javascript">
        function splash_start() {
        document.getElementById('splash_gif').style.opacity = "1";
        }
        function splash_stop() {
        document.getElementById('splash_gif').style.opacity = "0";
        }
        splash_stop()
        </script>-->
      </td>
      <td valign="top" width="75%">
            <a href="https://arxiv.org/pdf/2004.07213.pdf">
              <papertitle>Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims</papertitle>
            </a>
      <br>
          <a href="https://www.milesbrundage.com/">Miles Brundage*</a>,
          <a href="https://www.shaharavin.com/">Shahar Avin*</a>, 
          <a href="https://www.linkedin.com/in/jasmine-wang/">Jasmine Wang*</a>, 
          <a href="https://www.cser.ac.uk/team/haydn-belfield/">Haydn Belfield*</a>, 
          <a href="https://www.linkedin.com/in/gretchen-m-krueger-254a0351/">Gretchen Krueger*</a>, &mldr; , 
      <br>
          <strong>Ruth Fong</strong>, et al.
      <br>
        <em>arXiv</em>, 2020
      <br>
        <a href="https://arxiv.org/abs/2004.07213">arxiv</a> | 
        <a href="http://www.towardtrustworthyai.com/">project page</a> |
        <a href="bib/BrundageArXiv2020.bib" target="_blank">bibtex</a>
        <p></p>
        <p>
          This report suggests various steps that different stakeholders can take to make it easier to verify claims made about AI systems and their associated development processes. The authors believe the implementation of such mechanisms can help make progress on one component of the multifaceted problem of ensuring that AI development is conducted in a trustworthy fashion.
        </p>
      </td>
    </tr>


    <tr onmouseout="tripod_stop()" onmouseover="tripod_start()" class="highlight">
      <td width="25%">
        <div class="one">
        <div class="two" id="tripod_image"><img src="media/tripod_2.png" width="160" height="160" alt="tripod"></div>
        <img src="media/tripod_1.png" width="160" height="160" alt="tripod">
        </div>
        <script type="text/javascript">
        function tripod_start() {
        document.getElementById('tripod_image').style.opacity = "1";
        }
        function tripod_stop() {
        document.getElementById('tripod_image').style.opacity = "0";
        }
        tripod_stop()
        </script>
      </td>
      <td valign="top" width="75%">
            <a href="https://arxiv.org/abs/1910.08485">
              <papertitle>Understanding Deep Networks via Extremal Perturbations and Smooth Masks</papertitle>
            </a>
      <br>
          <strong>Ruth Fong*</strong>, <a href="https://www.linkedin.com/in/mandelapatrick/">Mandela Patrick</a>*, and <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>
      <br>
        <em>ICCV</em>, 2019 <font color="orange"><strong>(Oral)</strong></font><br>
        <a href="https://arxiv.org/abs/1910.08485">arxiv</a> | 
        <a href="http://ruthcfong.github.io/files/fong19_extremal_supps.pdf">supp</a> |
        <a href="http://ruthcfong.github.io/files/fong19_extremal_poster.pdf">poster</a> |
        <a href="https://github.com/facebookresearch/TorchRay">code (TorchRay)</a> | 
        <!-- TODO(ruthfong): Fix bibtex hyperlink -->
        <a href="https://youtu.be/qUu1076IMWo?t=633">4-min video</a> |
        <a href="bib/FongPatrickVedaldiICCV2019.bib" target="_blank">bibtex</a>
        <div style="display: none;" id="iccv19_bib">
          <pre>
@InProceedings{fong_iccv_2019,
author = {Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
title = {Understanding Deep Networks via Extremal Perturbations and Smooth Masks},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
year = {2019}
}
          </pre>
        </div>
        <p></p>
        <p>We introduce extremal perturbations, an novel attribution method that highlights "where" a model is "looking." We improve upon Fong and Vedaldi, 2017 by separating out regularization on the size and smoothness of a perturbation mask from the attribution objective of learning a mask that maximally affects a model's output; we also extend our work to intermediate channel representations.</p>
      </td>
    </tr>
    <tr onmouseout="wolves_stop()" onmouseover="wolves_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="wolves_image"><img src="media/wolves_2.png" width="160" height="160" alt="wolves"></div>
        <img src="media/wolves_1.png" width="160" height="160" alt="wolves">
        </div>
        <script type="text/javascript">
        function wolves_start() {
        document.getElementById('wolves_image').style.opacity = "1";
        }
        function wolves_stop() {
        document.getElementById('wolves_image').style.opacity = "0";
        }
        tripod_stop()
        </script>
      </td>
      <td valign="top" width="75%">
            <a href="http://arxiv.org/abs/1910.10651">
              <papertitle>Occlusions for Effective Data Augmentation in Image Classification</papertitle>
            </a>
      <br>
          <strong>Ruth Fong</strong> and <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>
      <br>
        <em>ICCV Workshop on Interpreting and Explaining Visual Artificial Intelligence Models</em>, 2019<br>
        <!--<a href="bib/FongVedaldiICCVWorkshop2019.bib" target="_blank">bibtex</a> | -->
        <a href="http://arxiv.org/abs/1910.10651">paper</a> |
        <a href="bib/FongVedaldiICCVW2019.bib" target="_blank">bibtex</a> |
        code (coming soon)
        <div style="display: none;" id="iccvworkshop19_bib">
          <pre>
@InProceedings{fong_iccv_workshop_2019,
author = {Fong, Ruth and and Vedaldi, Andrea},
title = {Occlusions for Effective Data Augmentation in Image Classification},
booktitle = {ICCV Workshop on Interpreting and Explaining Visual Artificial Intelligence Models},
year = {2019}
}
          </pre>
        </div>
        <p></p>
        <p>We introduce a simple paradigm based on batch augmentation for leveraging input-level occlusions (both stochastic and saliency-based) to improve ImageNet image classification. We also demonstrate the necessary of batch augmentation and quantify the robustness of different CNN architectures to occlusion via ablation studies.</p>
      </td>
    </tr>
    <tr onmouseout="filters_stop()" onmouseover="filters_start()" class="highlight">
      <td width="25%">
        <div class="one">
        <div class="two" id="filter_image"><img src="media/filters_2.png" width="160" height="160" alt="filters"></div>
        <img src="media/filters_1.png" width="160" height="160" alt="filters">
        </div>
        <script type="text/javascript">
        function filters_start() {
        document.getElementById('filter_image').style.opacity = "1";
        }
        function filters_stop() {
        document.getElementById('filter_image').style.opacity = "0";
        }
        filters_stop()
        </script>
      </td>
      <td valign="top" width="75%">
            <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Fong_Net2Vec_Quantifying_and_CVPR_2018_paper.pdf">
              <papertitle>Net2Vec: Quantifying and Explaining how Concepts are Encoded by Filters in Deep Neural Networks</papertitle>
            </a>
      <br>
          <strong>Ruth Fong</strong> and <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>
      <br>
        <em>CVPR</em>, 2018 <font color="orange"><strong>(Spotlight)</strong></font><br>
        <a href="https://arxiv.org/abs/1801.03454">arxiv</a> |
        <a href="http://ruthcfong.github.io/files/net2vec_supps.pdf">supp</a> |
        <a href="bib/FongVedaldiCVPR2018.bib" target="_blank">bibtex</a> |
        <!--<a onclick="toggle_bib('cvpr18_bib')">bibtex</a> /-->
        <a href="https://github.com/ruthcfong/net2vec">code</a> |
        <a href="https://www.youtube.com/watch?v=mDVD13M2X94&feature=youtu.be&t=4592">4-min video</a> |
        <a href="files/fong_cvpr18_net2vec_spotlight_slides.pdf">slides</a>
        <div style="display: none;" id="cvpr18_bib">
          <pre>
@InProceedings{fong_cvpr_2018,
  author={Fong, Ruth and Vedaldi, Andrea},
  title={Net2Vec: Quantifying and Explaining how Concepts 
  are Encoded by Filters in Deep Neural Networks},
  booktitle={The IEEE Conference on Computer Vision 
  and Pattern Recognition (CVPR)},
  month={July},
  year={2018}
}
          </pre>
        </div>
        <p></p>
        <p>Investigating how human-interpretable visual concepts (i.e., textures, objects, etc.) are encoded across hidden units of a convolutional neural network (CNN) layer as well as across CNN layers.</p>
      </td>
    </tr>

    <tr onmouseout="classifier_stop()" onmouseover="classifier_start()"><!-- class="highlight">-->
      <td width="25%">
        <div class="one">
        <div class="two" id = 'classifier_image'><img src='media/classifier_2.png' width="160" height="130"></div>
        <img src='media/classifier_1.png' width="160" height="130">
        </div>
        <script type="text/javascript">
        function classifier_start() {
        document.getElementById('classifier_image').style.opacity = "1";
        }
        function classifier_stop() {
        document.getElementById('classifier_image').style.opacity = "0";
        }
        classifier_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://www.nature.com/articles/s41598-018-23618-6">
        <papertitle>Using Human Brain Activity to Guide Machine Learning</papertitle></a>
        <br>
          <strong>Ruth Fong</strong>, <a href="https://www.wjscheirer.com/">Walter Scheirer</a>, and <a href="http://coxlab.org/">David Cox</a>
        <br>
        <em>Scientific Reports</em>, 2018<br>
        <a href="https://arxiv.org/abs/1703.05463">arxiv</a> |
        <a href="https://arxiv.org/src/1703.05463v2/anc/fong-et-al-supplementary.pdf">supp</a> |
        <a href="https://dash.harvard.edu/handle/1/14398538">Harvard thesis</a> |
        <a href="bib/FongScheirerCox2018.bib" target="_blank">bibtex</a>
        <!--code (coming soon)-->
        <p></p>
        <p>We introduce a biologically-informed machine learning paradigm for object classification that biases models to better match the learned, internal representations of the visual cortex.</p>
      </td>
    </tr>

    <tr onmouseout="flute_stop()" onmouseover="flute_start()" class="highlight">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'flute_image_2'><img src='media/flute_2.png' alt="flute" height="150" width="160"></div>
        <div class="two" id = 'flute_image_1'><img src='media/flute_1.png' alt="flute" height="150" width="160"></div>
        <!--<img src='media/flute_1.png' alt="flute" height="150" width="160">-->
        </div>
        <script type="text/javascript">
        function flute_start() {
        document.getElementById('flute_image_2').style.opacity = "1";
        document.getElementById('flute_image_1').style.opacity = "0";
        }
        function flute_stop() {
        document.getElementById('flute_image_2').style.opacity = "0";
        document.getElementById('flute_image_1').style.opacity = "1";
        }
        flute_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Fong_Interpretable_Explanations_of_ICCV_2017_paper.pdf">
        <papertitle>Interpretable Explanations of Black Box Algorithms by Meaningful Perturbation</papertitle>
        </a>
        <br>
          <strong>Ruth Fong</strong> and <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>
        <br>
        <em>ICCV</em>, 2017 <br>
        <a href="https://arxiv.org/abs/1704.03296">arxiv</a> |
        <a href="http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fong_Interpretable_Explanations_of_ICCV_2017_supplemental.pdf">supp</a> |
        <a href="bib/FongVedaldiICCV2017.bib" target="_blank">bibtex</a> |
        <a href="https://github.com/ruthcfong/perturb_explanations">code</a> |
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-28954-6_8">book chapter (extended)</a> |
        <a href="bib/FongVedaldiSpringer2019.bib" target="_blank">chapter bibtex</a>
        <p></p>
        <p>We developed a theoretical framework for learning "explanations" of black box functions like CNNs as well as saliency methods for identifying "where" a computer vision algorithm is looking.</p>
      </td>
    </tr>
  </table>

<br><br>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td>
      <heading>Theses &#127891;</heading>
      </td>
    </tr>
    </table>
    <table width="100%" align="center" border="0" cellpadding="20">

    <tr>
    <!--<tr onmouseout="selectivity_stop()" onmouseover="selectivity_start()">-->
      <td width="25%">
        <!--<img src="media/belt_crest.pdf" style="display: block;margin-left: 25; margin-right: 15;width: 130;">-->
        <img src="media/oxford_circle_logo.png" style="display: block;margin-left: 25; margin-right: 15;width: 130;">
        <!--<div class="one">
        <div class="two" id = 'selectivity_image_2'><img src='media/sounds_2.png' width="160" height="130"></div>
        <div class="two" id = 'selectivity_image_1'><img src='media/sounds_1.png' width="160" height="130"></div>-->
        <!--<img src='media/selectivity_1.png' width="160" height="130">-->
        <!--</div>-->
        <!--<script type="text/javascript">
        function selectivity_start() {
        document.getElementById('selectivity_image_2').style.opacity = "1";
        document.getElementById('selectivity_image_1').style.opacity = "0";
        }
        function selectivity_stop() {
        document.getElementById('selectivity_image_2').style.opacity = "0";
        document.getElementById('selectivity_image_1').style.opacity = "1";
        }
        selectivity_stop()
        </script>-->
      </td>
      <td valign="top" width="75%">
        <p><a href="files/fong20_thesis.pdf">
        <papertitle>Understanding Convolutional Neural Networks</papertitle></a>
        <br>
          <strong>Ruth Fong</strong> (advised by <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>)
        <br>
        <em>Ph.D. Thesis</em><br>
        <p></p>
        <p>This is a "thesis-by-staples", so the novel parts are the non-paper chapters (i.e. all chapters except chapters 3-6), which I wrote with accessibility in mind (e.g., the ideal reader is a motivated undergraduate or graduate student looking to learn more about deep learning and interpretability). The introduction is accessible to a high-school student, and appendices A and B are primers on the relevant math concepts and convolutional neural networks respectively. 
        </p>
      </td>
    </tr>
    

    <tr onmouseout="selectivity_stop()" onmouseover="selectivity_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'selectivity_image_2'><img src='media/sounds_2.png' width="160" height="130"></div>
        <div class="two" id = 'selectivity_image_1'><img src='media/sounds_1.png' width="160" height="130"></div>
        <!--<img src='media/selectivity_1.png' width="160" height="130">-->
        </div>
        <script type="text/javascript">
        function selectivity_start() {
        document.getElementById('selectivity_image_2').style.opacity = "1";
        document.getElementById('selectivity_image_1').style.opacity = "0";
        }
        function selectivity_stop() {
        document.getElementById('selectivity_image_2').style.opacity = "0";
        document.getElementById('selectivity_image_1').style.opacity = "1";
        }
        selectivity_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="files/fong16_msc_thesis_modelling.pdf">
        <papertitle>Modelling Blind Single Channel Sound Separation Using Predict Neural Networks</papertitle></a>
        <br>
          <strong>Ruth Fong</strong> (advised by <a href="https://www.dpag.ox.ac.uk/team/benjamin-willmore">Ben Willmore</a> and <a href="https://scholar.google.com/citations?user=GUALUxwAAAAJ">Nicol Harper</a>)
        <br>
        <em>M.Sc. Thesis #2</em><br>
        <p></p>
        <p>I developed an unsupervised learning paradigm for sound separation using fully connected and recurrent neural networks to predict the future from past cochleagram data.</p>
      </td>
    </tr>

    <tr onmouseout="simulation_stop()" onmouseover="simulation_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'simulation_gif'><img src='media/simulation.gif' width="160" height="160"></div>
        <img src='media/simulation_start.png' width="160" height="160">
        </div>
        <script type="text/javascript">
        function simulation_start() {
        document.getElementById('simulation_gif').style.opacity = "1";
        }
        function simulation_stop() {
        document.getElementById('simulation_gif').style.opacity = "0";
        }
        simulation_stop()
        </script>
      </td>
      <td valign="top" width="75%">
          <p><!--<a href="https://www.dropbox.com/s/6vokwoxqmwvwpvu/Ruth%20Fong%20-%20MSc%20Neuroscience%20Dissertation%20-%20Optimizing%20Deep%20Brain%20Stimulation%20to%20Dampen%20Tremor.pdf?dl=0">-->
          <a href="files/ruth_fong_msc_dissertation_deep_brain_stimulation.pdf">
        <papertitle>Optimizing Deep Brain Stimulation to Dampen Tremor</papertitle></a>
        <br>
          <strong>Ruth Fong</strong> (advised by <a href="https://www.ndcn.ox.ac.uk/team/rafal-bogacz">Rafal Bogacz</a>)
        <br>
        <em>M.Sc. Thesis #1</em><br>
        <a href="http://ruthcfong.github.io/kuramoto/tutorial.html">Tutorial</a> | 
        <a href="https://data.mrc.ox.ac.uk/data-set/kuramoto">Demo </a> |
        <a href="http://uk.mathworks.com/matlabcentral/fileexchange/56485-family-of-rayleigh-statistics-toolbox">MATLAB Rayleigh statistics toolbox</a>
          <!--<a href="http://ruthcfong.github.io/kuramoto/">Demo</a>-->
        <p></p>
        <p>I developed a computational oscillator model that modeled the tremor-dampening effects of phasic deep brain stimulation and analyzed it on experimental data.</p>
      </td>
    </tr>

    <tr>
    <!--<tr onmouseout="selectivity_stop()" onmouseover="selectivity_start()">-->
      <td width="25%">
        <img src="media/harvard_shield_logo.png" width="160">
        <!--<div class="one">
        <div class="two" id = 'selectivity_image_2'><img src='media/sounds_2.png' width="160" height="130"></div>
        <div class="two" id = 'selectivity_image_1'><img src='media/sounds_1.png' width="160" height="130"></div>-->
        <!--<img src='media/selectivity_1.png' width="160" height="130">-->
        <!--</div>-->
        <!--<script type="text/javascript">
        function selectivity_start() {
        document.getElementById('selectivity_image_2').style.opacity = "1";
        document.getElementById('selectivity_image_1').style.opacity = "0";
        }
        function selectivity_stop() {
        document.getElementById('selectivity_image_2').style.opacity = "0";
        document.getElementById('selectivity_image_1').style.opacity = "1";
        }
        selectivity_stop()
        </script>-->
      </td>
      <td valign="top" width="75%">
        <p><a href="https://dash.harvard.edu/handle/1/14398538">
        <papertitle>Leveraging Human Brain Activity to Improve Object Classification</papertitle></a>
        <br>
          <strong>Ruth Fong</strong> (advised by <a href="http://coxlab.org/">David Cox</a> and <a href="https://www.wjscheirer.com/">Walter Scheirer</a>)
        <br>
        <em>A.B. Thesis</em><br>
        <p></p>
        <p>Published as <a href="https://www.nature.com/articles/s41598-018-23618-6">Fong et al., Scientific Reports 2018</a>.
        </p>
      </td>
    </tr>

    </table>
<!--
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Course Projects</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
    <tr onmouseout="dna_stop()" onmouseover="dna_start()">
      <td width="25%">
        <div class="one">
        <div align="center" class="two" id='dna_gif'><img src='media/dna.gif' width="100" height="160"></div>
        <div align="center" class="two" id='dna_image'><img src='media/dna_start.png' width="100" height="160"></div>
        </div>
        <script type="text/javascript">
        function dna_start() {
        document.getElementById('dna_gif').style.opacity = "1";
        document.getElementById('dna_image').style.opacity = "0";
        }
        function dna_stop() {
        document.getElementById('dna_gif').style.opacity = "0";
        document.getElementById('dna_image').style.opacity = "1";
        }
        dna_stop()
        </script>
      </td>
        <td width="75%" valign="top">
        <p>
          <a href="https://www.dropbox.com/s/prahduk551ti3hn/cs227r-fong-li-final-paper.pdf?dl=0">
          <papertitle>Ensuring Privacy for Genomics Data with K Disease Categories</papertitle>
          </a>
          <br>
          <strong>Ruth Fong</strong> and <a href="http://louisrli.github.io/">Louis Li</a>, 2014
        <p><br>
          We generalized differentially private data-release mechanisms for genomics data linked to K possible disease categories for <a href="https://privacytools.seas.harvard.edu/classes/cs-227r-topics-cryptograph-and-privacy">CS 227r: Differential Privacy</a>.
        </p>
        </p>
        </td>
      </tr>

      <tr onmouseout="otter_stop()" onmouseover="otter_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="otter_image"><img src="media/benedict_2.png" width="160" height="160"></div>
        <img src="media/benedict_1.png" width="160" height="160">
        </div>
        <script type="text/javascript">
        function otter_start() {
        document.getElementById('otter_image').style.opacity = "1";
        }
        function otter_stop() {
        document.getElementById('otter_image').style.opacity = "0";
        }
        otter_stop()
        </script>
      </td>
        <td width="75%" valign="top">
        <p>
          <a href="https://www.dropbox.com/s/nq9jd7rsm6p27yr/fong_ruth_final_report.pdf?dl=0">
          <papertitle>Human-Animal Look-a-likes: Exploring measures of similarity across object categories</papertitle>
          </a>
          <br>
          <strong>Ruth Fong</strong>, 2013
        <p><br>
          I developed a matching paradigm for pairing similar-looking human and animal faces for <a href="https://locator.tlt.harvard.edu/course/colgsas-113944">CS 283: Computer Vision</a>. 
        </p>
        </p>
        </td>
      </tr>
      </table>
-->

<br><br>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Teaching &#128221;</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr onmouseout="pigeon_stop()" onmouseover="pigeon_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id="pigeon_image"><img src="media/pigeons_2.jpg" width="160" height="160" alt="pigeons"></div>
        <img src="media/pigeons_1.jpg" width="160" height="160" alt="pigeons">
        </div>
        <script type="text/javascript">
        function pigeon_start() {
        document.getElementById('pigeon_image').style.opacity = "1";
        }
        function pigeon_stop() {
        document.getElementById('pigeon_image').style.opacity = "0";
        }
        pigeon_stop()
        </script>
      </td>
      <!--<tr>
        <td width="25%"><img src="media/TooManyPigeons.jpg" alt="pigeons" width="160" height="160"></td>-->
        <td width="75%" valign="center">
        <p>
          <a href="https://www.cs.princeton.edu/courses/archive/fall22/cos324/">
          <papertitle>Princeton COS324: Intro to Machine Learning &mdash; Fall 2022 & Spring 2023</papertitle>
          </a>
          <br>
          <a href="https://www.cs.princeton.edu/~cos126/">
          <papertitle>Princeton COS126: CS: An Interdisciplinary Approach &mdash; Fall 2021 & Spring 2022</papertitle>
          </a>
          <br>
          <a href="https://www.cs.princeton.edu/courses/archive/fall21/cos126/">
          <papertitle>Oxford Engineering B14: Image and Signal Analysis &mdash; Fall 2019</papertitle>
          </a>
          <br>          
          <a href="http://soe.rutgers.edu/new-jersey-governors-school-engineering-technology">
          <papertitle>NJ Governor's School: Mathematics in the World &mdash; Summer 2015</papertitle>
          </a>
          <br>
          <a href="https://lewis.seas.harvard.edu/pages/computer-science-121-and-csci-e-121-introduction-theory-computation">
          <papertitle>Harvard CS121: Intro to Theory of Computation &mdash; Fall 2014</papertitle>
          </a>
          <br>
          <a href="https://www.seas.harvard.edu/courses/cs20/">
          <papertitle>Harvard CS20: Intro to Discrete Math &mdash; Spring 2014</papertitle>
          </a>
          <br>
          <a href="https://cs50.harvard.edu/">
          <papertitle>Harvard CS50: Intro to CS I &mdash; Fall 2012</papertitle>
          </a>
          <br>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          <a href="https://jonbarron.info/">This ubiquitous CS researcher website template spawned from here.</a>
          <br>
          Last updated: December 2022
        </font>
        </p>
        </td>
      </tr>
      </table>
      <!--<script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("G-RS81Q5DB6F");
          pageTracker._trackPageview();
          } catch(err) {}

      function toggle_bib(bib_id) {
        if (document.getElementById(bib_id).style.display=='none')
          document.getElementById(bib_id).style.display='block';
        else
          document.getElementById(bib_id).style.display='none';
      }
      /*
      var txtFile = new XMLHttpRequest();
      txtFile.open("GET", "bib/FongVedaldiCVPR2018.txt", true);
      // allText = txtFile.responseText;
      txtFile.onreadystatechange = function() {
        if (txtFile.readyState === 4 && txtFile.status == 200) {
           // allText = txtFile.responseText;
           alert(txtFile.responseText);
           document.getElementById('cvpr18_bib').innerHTML = txtFile.responseText;
        }
      }
      */
      // document.getElementById('cvpr18_bib').innerHTML = allText;
      </script>-->
    </td>
    </tr>
  </table>
  </body>
</html>
